Not using distributed mode
Creating model: repvit_m0_9
number of params: 5489328
Creating teacher model: regnety_160
RepViT(
  (features): ModuleList(
    (0): Sequential(
      (0): Conv2d_BN(
        (c): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): GELU(approximate='none')
      (2): Conv2d_BN(
        (c): Conv2d(24, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): RepViTBlock(
      (token_mixer): Sequential(
        (0): RepVGGDW(
          (conv): Conv2d_BN(
            (c): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
            (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), groups=48)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): SEModule(
          (fc1): Conv2d(48, 16, kernel_size=(1, 1), stride=(1, 1))
          (bn): Identity()
          (act): ReLU(inplace=True)
          (fc2): Conv2d(16, 48, kernel_size=(1, 1), stride=(1, 1))
          (gate): Sigmoid()
        )
      )
      (channel_mixer): Residual(
        (m): Sequential(
          (0): Conv2d_BN(
            (c): Conv2d(48, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): GELU(approximate='none')
          (2): Conv2d_BN(
            (c): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (2-3): 2 x RepViTBlock(
      (token_mixer): Sequential(
        (0): RepVGGDW(
          (conv): Conv2d_BN(
            (c): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)
            (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), groups=48)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Identity()
      )
      (channel_mixer): Residual(
        (m): Sequential(
          (0): Conv2d_BN(
            (c): Conv2d(48, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): GELU(approximate='none')
          (2): Conv2d_BN(
            (c): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (4): RepViTBlock(
      (token_mixer): Sequential(
        (0): Conv2d_BN(
          (c): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Identity()
        (2): Conv2d_BN(
          (c): Conv2d(48, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (channel_mixer): Residual(
        (m): Sequential(
          (0): Conv2d_BN(
            (c): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): GELU(approximate='none')
          (2): Conv2d_BN(
            (c): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (5): RepViTBlock(
      (token_mixer): Sequential(
        (0): RepVGGDW(
          (conv): Conv2d_BN(
            (c): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
            (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), groups=96)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): SEModule(
          (fc1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))
          (bn): Identity()
          (act): ReLU(inplace=True)
          (fc2): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))
          (gate): Sigmoid()
        )
      )
      (channel_mixer): Residual(
        (m): Sequential(
          (0): Conv2d_BN(
            (c): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): GELU(approximate='none')
          (2): Conv2d_BN(
            (c): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (6-7): 2 x RepViTBlock(
      (token_mixer): Sequential(
        (0): RepVGGDW(
          (conv): Conv2d_BN(
            (c): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
            (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), groups=96)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Identity()
      )
      (channel_mixer): Residual(
        (m): Sequential(
          (0): Conv2d_BN(
            (c): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): GELU(approximate='none')
          (2): Conv2d_BN(
            (c): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (8): RepViTBlock(
      (token_mixer): Sequential(
        (0): Conv2d_BN(
          (c): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Identity()
        (2): Conv2d_BN(
          (c): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (channel_mixer): Residual(
        (m): Sequential(
          (0): Conv2d_BN(
            (c): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): GELU(approximate='none')
          (2): Conv2d_BN(
            (c): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (9): RepViTBlock(
      (token_mixer): Sequential(
        (0): RepVGGDW(
          (conv): Conv2d_BN(
            (c): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
            (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), groups=192)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): SEModule(
          (fc1): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))
          (bn): Identity()
          (act): ReLU(inplace=True)
          (fc2): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
          (gate): Sigmoid()
        )
      )
      (channel_mixer): Residual(
        (m): Sequential(
          (0): Conv2d_BN(
            (c): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): GELU(approximate='none')
          (2): Conv2d_BN(
            (c): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (10): RepViTBlock(
      (token_mixer): Sequential(
        (0): RepVGGDW(
          (conv): Conv2d_BN(
            (c): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
            (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), groups=192)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Identity()
      )
      (channel_mixer): Residual(
        (m): Sequential(
          (0): Conv2d_BN(
            (c): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): GELU(approximate='none')
          (2): Conv2d_BN(
            (c): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (11): RepViTBlock(
      (token_mixer): Sequential(
        (0): RepVGGDW(
          (conv): Conv2d_BN(
            (c): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
            (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), groups=192)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): SEModule(
          (fc1): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))
          (bn): Identity()
          (act): ReLU(inplace=True)
          (fc2): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
          (gate): Sigmoid()
        )
      )
      (channel_mixer): Residual(
        (m): Sequential(
          (0): Conv2d_BN(
            (c): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): GELU(approximate='none')
          (2): Conv2d_BN(
            (c): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (12): RepViTBlock(
      (token_mixer): Sequential(
        (0): RepVGGDW(
          (conv): Conv2d_BN(
            (c): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
            (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), groups=192)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Identity()
      )
      (channel_mixer): Residual(
        (m): Sequential(
          (0): Conv2d_BN(
            (c): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): GELU(approximate='none')
          (2): Conv2d_BN(
            (c): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (13): RepViTBlock(
      (token_mixer): Sequential(
        (0): RepVGGDW(
          (conv): Conv2d_BN(
            (c): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
            (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), groups=192)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): SEModule(
          (fc1): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))
          (bn): Identity()
          (act): ReLU(inplace=True)
          (fc2): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
          (gate): Sigmoid()
        )
      )
      (channel_mixer): Residual(
        (m): Sequential(
          (0): Conv2d_BN(
            (c): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): GELU(approximate='none')
          (2): Conv2d_BN(
            (c): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (14): RepViTBlock(
      (token_mixer): Sequential(
        (0): RepVGGDW(
          (conv): Conv2d_BN(
            (c): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
            (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), groups=192)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Identity()
      )
      (channel_mixer): Residual(
        (m): Sequential(
          (0): Conv2d_BN(
            (c): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): GELU(approximate='none')
          (2): Conv2d_BN(
            (c): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (15): RepViTBlock(
      (token_mixer): Sequential(
        (0): RepVGGDW(
          (conv): Conv2d_BN(
            (c): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
            (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), groups=192)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): SEModule(
          (fc1): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))
          (bn): Identity()
          (act): ReLU(inplace=True)
          (fc2): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
          (gate): Sigmoid()
        )
      )
      (channel_mixer): Residual(
        (m): Sequential(
          (0): Conv2d_BN(
            (c): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): GELU(approximate='none')
          (2): Conv2d_BN(
            (c): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (16): RepViTBlock(
      (token_mixer): Sequential(
        (0): RepVGGDW(
          (conv): Conv2d_BN(
            (c): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
            (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), groups=192)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Identity()
      )
      (channel_mixer): Residual(
        (m): Sequential(
          (0): Conv2d_BN(
            (c): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): GELU(approximate='none')
          (2): Conv2d_BN(
            (c): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (17): RepViTBlock(
      (token_mixer): Sequential(
        (0): RepVGGDW(
          (conv): Conv2d_BN(
            (c): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
            (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), groups=192)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): SEModule(
          (fc1): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))
          (bn): Identity()
          (act): ReLU(inplace=True)
          (fc2): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
          (gate): Sigmoid()
        )
      )
      (channel_mixer): Residual(
        (m): Sequential(
          (0): Conv2d_BN(
            (c): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): GELU(approximate='none')
          (2): Conv2d_BN(
            (c): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (18): RepViTBlock(
      (token_mixer): Sequential(
        (0): RepVGGDW(
          (conv): Conv2d_BN(
            (c): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
            (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), groups=192)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Identity()
      )
      (channel_mixer): Residual(
        (m): Sequential(
          (0): Conv2d_BN(
            (c): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): GELU(approximate='none')
          (2): Conv2d_BN(
            (c): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (19): RepViTBlock(
      (token_mixer): Sequential(
        (0): RepVGGDW(
          (conv): Conv2d_BN(
            (c): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
            (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), groups=192)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): SEModule(
          (fc1): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))
          (bn): Identity()
          (act): ReLU(inplace=True)
          (fc2): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
          (gate): Sigmoid()
        )
      )
      (channel_mixer): Residual(
        (m): Sequential(
          (0): Conv2d_BN(
            (c): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): GELU(approximate='none')
          (2): Conv2d_BN(
            (c): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (20): RepViTBlock(
      (token_mixer): Sequential(
        (0): RepVGGDW(
          (conv): Conv2d_BN(
            (c): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
            (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), groups=192)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Identity()
      )
      (channel_mixer): Residual(
        (m): Sequential(
          (0): Conv2d_BN(
            (c): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): GELU(approximate='none')
          (2): Conv2d_BN(
            (c): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (21): RepViTBlock(
      (token_mixer): Sequential(
        (0): RepVGGDW(
          (conv): Conv2d_BN(
            (c): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
            (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), groups=192)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): SEModule(
          (fc1): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))
          (bn): Identity()
          (act): ReLU(inplace=True)
          (fc2): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
          (gate): Sigmoid()
        )
      )
      (channel_mixer): Residual(
        (m): Sequential(
          (0): Conv2d_BN(
            (c): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): GELU(approximate='none')
          (2): Conv2d_BN(
            (c): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (22-23): 2 x RepViTBlock(
      (token_mixer): Sequential(
        (0): RepVGGDW(
          (conv): Conv2d_BN(
            (c): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
            (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), groups=192)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Identity()
      )
      (channel_mixer): Residual(
        (m): Sequential(
          (0): Conv2d_BN(
            (c): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): GELU(approximate='none')
          (2): Conv2d_BN(
            (c): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (24): RepViTBlock(
      (token_mixer): Sequential(
        (0): Conv2d_BN(
          (c): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Identity()
        (2): Conv2d_BN(
          (c): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (channel_mixer): Residual(
        (m): Sequential(
          (0): Conv2d_BN(
            (c): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): GELU(approximate='none')
          (2): Conv2d_BN(
            (c): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (25): RepViTBlock(
      (token_mixer): Sequential(
        (0): RepVGGDW(
          (conv): Conv2d_BN(
            (c): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv1): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), groups=384)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): SEModule(
          (fc1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))
          (bn): Identity()
          (act): ReLU(inplace=True)
          (fc2): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
          (gate): Sigmoid()
        )
      )
      (channel_mixer): Residual(
        (m): Sequential(
          (0): Conv2d_BN(
            (c): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): GELU(approximate='none')
          (2): Conv2d_BN(
            (c): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
    )
    (26): RepViTBlock(
      (token_mixer): Sequential(
        (0): RepVGGDW(
          (conv): Conv2d_BN(
            (c): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv1): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), groups=384)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Identity()
      )
      (channel_mixer): Residual(
        (m): Sequential(
          (0): Conv2d_BN(
            (c): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): GELU(approximate='none')
          (2): Conv2d_BN(
            (c): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (classifier): Classfier(
    (classifier): BN_Linear(
      (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (l): Linear(in_features=384, out_features=1000, bias=True)
    )
    (classifier_dist): BN_Linear(
      (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (l): Linear(in_features=384, out_features=1000, bias=True)
    )
  )
)
{
  "batch_size": 256,
  "epochs": 300,
  "model": "repvit_m0_9",
  "input_size": 224,
  "model_ema": true,
  "model_ema_decay": 0.99996,
  "model_ema_force_cpu": false,
  "opt": "adamw",
  "opt_eps": 1e-08,
  "opt_betas": null,
  "clip_grad": 0.02,
  "clip_mode": "agc",
  "momentum": 0.9,
  "weight_decay": 0.025,
  "sched": "cosine",
  "lr": 0.0005,
  "lr_noise": null,
  "lr_noise_pct": 0.67,
  "lr_noise_std": 1.0,
  "warmup_lr": 1e-06,
  "min_lr": 1e-05,
  "decay_epochs": 30,
  "warmup_epochs": 5,
  "cooldown_epochs": 10,
  "patience_epochs": 10,
  "decay_rate": 0.1,
  "ThreeAugment": false,
  "color_jitter": 0.4,
  "aa": "rand-m9-mstd0.5-inc1",
  "smoothing": 0.1,
  "train_interpolation": "bicubic",
  "repeated_aug": true,
  "reprob": 0.25,
  "remode": "pixel",
  "recount": 1,
  "resplit": false,
  "mixup": 0.8,
  "cutmix": 1.0,
  "cutmix_minmax": null,
  "mixup_prob": 1.0,
  "mixup_switch_prob": 0.5,
  "mixup_mode": "batch",
  "teacher_model": "regnety_160",
  "teacher_path": "https://dl.fbaipublicfiles.com/deit/regnety_160-a5fe301d.pth",
  "distillation_type": "hard",
  "distillation_alpha": 0.5,
  "distillation_tau": 1.0,
  "finetune": "",
  "set_bn_eval": false,
  "data_path": "/home2/keunsoo/imagenet",
  "data_set": "IMNET",
  "inat_category": "name",
  "output_dir": "checkpoints/repvit_m0_9/2024_06_07_16_57_33",
  "device": "cuda",
  "seed": 0,
  "resume": "./checkpoints/repvit_m0_9_distill_300e.pth",
  "start_epoch": 0,
  "eval": true,
  "dist_eval": false,
  "num_workers": 10,
  "pin_mem": true,
  "world_size": 1,
  "dist_url": "env://",
  "save_freq": 1,
  "quantize": false,
  "prune": false,
  "deploy": false,
  "project": "repvit",
  "distributed": false,
  "nb_classes": 1000
}

Loading local checkpoint at ./checkpoints/repvit_m0_9_distill_300e.pth
<All keys matched successfully>

    sparsity=0.10: accuracy=78.71%
    sparsity=0.20: accuracy=78.71%
    sparsity=0.30: accuracy=78.71%
    sparsity=0.40: accuracy=78.71%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[78.71%, 78.71%, 78.71%, 78.71%]
    sparsity=0.10: accuracy=76.82%
    sparsity=0.20: accuracy=76.82%
    sparsity=0.30: accuracy=76.82%
    sparsity=0.40: accuracy=76.82%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[76.82%, 76.82%, 76.82%, 76.82%]
    sparsity=0.10: accuracy=76.82%
    sparsity=0.20: accuracy=76.82%
    sparsity=0.30: accuracy=76.82%
    sparsity=0.40: accuracy=76.82%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[76.82%, 76.82%, 76.82%, 76.82%]
    sparsity=0.10: accuracy=76.82%
    sparsity=0.20: accuracy=76.82%
    sparsity=0.30: accuracy=76.82%
    sparsity=0.40: accuracy=76.82%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[76.82%, 76.82%, 76.82%, 76.82%]
    sparsity=0.10: accuracy=76.72%
    sparsity=0.20: accuracy=76.72%
    sparsity=0.30: accuracy=76.72%
    sparsity=0.40: accuracy=76.72%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[76.72%, 76.72%, 76.72%, 76.72%]
    sparsity=0.10: accuracy=76.72%
    sparsity=0.20: accuracy=76.72%
    sparsity=0.30: accuracy=76.72%
    sparsity=0.40: accuracy=76.72%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[76.72%, 76.72%, 76.72%, 76.72%]
    sparsity=0.10: accuracy=76.23%
    sparsity=0.20: accuracy=76.23%
    sparsity=0.30: accuracy=76.23%
    sparsity=0.40: accuracy=76.23%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[76.23%, 76.23%, 76.23%, 76.23%]
    sparsity=0.10: accuracy=75.14%
    sparsity=0.20: accuracy=75.14%
    sparsity=0.30: accuracy=75.14%
    sparsity=0.40: accuracy=75.14%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[75.14%, 75.14%, 75.14%, 75.14%]
    sparsity=0.10: accuracy=75.14%
    sparsity=0.20: accuracy=75.14%
    sparsity=0.30: accuracy=75.14%
    sparsity=0.40: accuracy=75.14%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[75.14%, 75.14%, 75.14%, 75.14%]
    sparsity=0.10: accuracy=75.14%
    sparsity=0.20: accuracy=75.14%
    sparsity=0.30: accuracy=75.14%
    sparsity=0.40: accuracy=75.14%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[75.14%, 75.14%, 75.14%, 75.14%]
    sparsity=0.10: accuracy=74.45%
    sparsity=0.20: accuracy=74.45%
    sparsity=0.30: accuracy=74.45%
    sparsity=0.40: accuracy=74.45%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[74.45%, 74.45%, 74.45%, 74.45%]
    sparsity=0.10: accuracy=70.19%
    sparsity=0.20: accuracy=70.19%
    sparsity=0.30: accuracy=70.19%
    sparsity=0.40: accuracy=70.19%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[70.19%, 70.19%, 70.19%, 70.19%]
    sparsity=0.10: accuracy=70.19%
    sparsity=0.20: accuracy=70.19%
    sparsity=0.30: accuracy=70.19%
    sparsity=0.40: accuracy=70.19%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[70.19%, 70.19%, 70.19%, 70.19%]
    sparsity=0.10: accuracy=70.19%
    sparsity=0.20: accuracy=70.19%
    sparsity=0.30: accuracy=70.19%
    sparsity=0.40: accuracy=70.19%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[70.19%, 70.19%, 70.19%, 70.19%]
    sparsity=0.10: accuracy=69.94%
    sparsity=0.20: accuracy=69.94%
    sparsity=0.30: accuracy=69.94%
    sparsity=0.40: accuracy=69.94%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[69.94%, 69.94%, 69.94%, 69.94%]
    sparsity=0.10: accuracy=49.29%
    sparsity=0.20: accuracy=49.29%
    sparsity=0.30: accuracy=49.29%
    sparsity=0.40: accuracy=49.29%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[49.29%, 49.29%, 49.29%, 49.29%]
    sparsity=0.10: accuracy=49.29%
    sparsity=0.20: accuracy=49.29%
    sparsity=0.30: accuracy=49.29%
    sparsity=0.40: accuracy=49.29%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[49.29%, 49.29%, 49.29%, 49.29%]
    sparsity=0.10: accuracy=26.63%
    sparsity=0.20: accuracy=26.63%
    sparsity=0.30: accuracy=26.63%
    sparsity=0.40: accuracy=26.63%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[26.63%, 26.63%, 26.63%, 26.63%]
    sparsity=0.10: accuracy=28.90%
    sparsity=0.20: accuracy=28.90%
    sparsity=0.30: accuracy=28.90%
    sparsity=0.40: accuracy=28.90%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[28.90%, 28.90%, 28.90%, 28.90%]
    sparsity=0.10: accuracy=23.16%
    sparsity=0.20: accuracy=23.16%
    sparsity=0.30: accuracy=23.16%
    sparsity=0.40: accuracy=23.16%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[23.16%, 23.16%, 23.16%, 23.16%]
    sparsity=0.10: accuracy=23.16%
    sparsity=0.20: accuracy=23.16%
    sparsity=0.30: accuracy=23.16%
    sparsity=0.40: accuracy=23.16%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[23.16%, 23.16%, 23.16%, 23.16%]
    sparsity=0.10: accuracy=23.16%
    sparsity=0.20: accuracy=23.16%
    sparsity=0.30: accuracy=23.16%
    sparsity=0.40: accuracy=23.16%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[23.16%, 23.16%, 23.16%, 23.16%]
    sparsity=0.10: accuracy=23.78%
    sparsity=0.20: accuracy=23.78%
    sparsity=0.30: accuracy=23.78%
    sparsity=0.40: accuracy=23.78%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[23.78%, 23.78%, 23.78%, 23.78%]
    sparsity=0.10: accuracy=24.74%
    sparsity=0.20: accuracy=24.74%
    sparsity=0.30: accuracy=24.74%
    sparsity=0.40: accuracy=24.74%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[24.74%, 24.74%, 24.74%, 24.74%]
    sparsity=0.10: accuracy=23.89%
    sparsity=0.20: accuracy=23.89%
    sparsity=0.30: accuracy=23.89%
    sparsity=0.40: accuracy=23.89%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[23.89%, 23.89%, 23.89%, 23.89%]
    sparsity=0.10: accuracy=24.55%
    sparsity=0.20: accuracy=24.55%
    sparsity=0.30: accuracy=24.55%
    sparsity=0.40: accuracy=24.55%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[24.55%, 24.55%, 24.55%, 24.55%]
    sparsity=0.10: accuracy=24.55%
    sparsity=0.20: accuracy=24.55%
    sparsity=0.30: accuracy=24.55%
    sparsity=0.40: accuracy=24.55%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[24.55%, 24.55%, 24.55%, 24.55%]
    sparsity=0.10: accuracy=24.55%
    sparsity=0.20: accuracy=24.55%
    sparsity=0.30: accuracy=24.55%
    sparsity=0.40: accuracy=24.55%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[24.55%, 24.55%, 24.55%, 24.55%]
    sparsity=0.10: accuracy=26.59%
    sparsity=0.20: accuracy=26.59%
    sparsity=0.30: accuracy=26.59%
    sparsity=0.40: accuracy=26.59%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[26.59%, 26.59%, 26.59%, 26.59%]
    sparsity=0.10: accuracy=24.45%
    sparsity=0.20: accuracy=24.45%
    sparsity=0.30: accuracy=24.45%
    sparsity=0.40: accuracy=24.45%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[24.45%, 24.45%, 24.45%, 24.45%]
    sparsity=0.10: accuracy=24.45%
    sparsity=0.20: accuracy=24.45%
    sparsity=0.30: accuracy=24.45%
    sparsity=0.40: accuracy=24.45%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[24.45%, 24.45%, 24.45%, 24.45%]
    sparsity=0.10: accuracy=24.45%
    sparsity=0.20: accuracy=24.45%
    sparsity=0.30: accuracy=24.45%
    sparsity=0.40: accuracy=24.45%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[24.45%, 24.45%, 24.45%, 24.45%]
    sparsity=0.10: accuracy=25.67%
    sparsity=0.20: accuracy=25.67%
    sparsity=0.30: accuracy=25.67%
    sparsity=0.40: accuracy=25.67%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[25.67%, 25.67%, 25.67%, 25.67%]
    sparsity=0.10: accuracy=21.84%
    sparsity=0.20: accuracy=21.84%
    sparsity=0.30: accuracy=21.84%
    sparsity=0.40: accuracy=21.84%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[21.84%, 21.84%, 21.84%, 21.84%]
    sparsity=0.10: accuracy=21.84%
    sparsity=0.20: accuracy=21.84%
    sparsity=0.30: accuracy=21.84%
    sparsity=0.40: accuracy=21.84%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[21.84%, 21.84%, 21.84%, 21.84%]
    sparsity=0.10: accuracy=14.05%
    sparsity=0.20: accuracy=14.05%
    sparsity=0.30: accuracy=14.05%
    sparsity=0.40: accuracy=14.05%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[14.05%, 14.05%, 14.05%, 14.05%]
    sparsity=0.10: accuracy=13.05%
    sparsity=0.20: accuracy=13.05%
    sparsity=0.30: accuracy=13.05%
    sparsity=0.40: accuracy=13.05%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[13.05%, 13.05%, 13.05%, 13.05%]
    sparsity=0.10: accuracy=12.75%
    sparsity=0.20: accuracy=12.75%
    sparsity=0.30: accuracy=12.75%
    sparsity=0.40: accuracy=12.75%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[12.75%, 12.75%, 12.75%, 12.75%]
    sparsity=0.10: accuracy=12.75%
    sparsity=0.20: accuracy=12.75%
    sparsity=0.30: accuracy=12.75%
    sparsity=0.40: accuracy=12.75%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[12.75%, 12.75%, 12.75%, 12.75%]
    sparsity=0.10: accuracy=12.75%
    sparsity=0.20: accuracy=12.75%
    sparsity=0.30: accuracy=12.75%
    sparsity=0.40: accuracy=12.75%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[12.75%, 12.75%, 12.75%, 12.75%]
    sparsity=0.10: accuracy=11.38%
    sparsity=0.20: accuracy=11.38%
    sparsity=0.30: accuracy=11.38%
    sparsity=0.40: accuracy=11.38%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[11.38%, 11.38%, 11.38%, 11.38%]
    sparsity=0.10: accuracy=11.42%
    sparsity=0.20: accuracy=11.42%
    sparsity=0.30: accuracy=11.42%
    sparsity=0.40: accuracy=11.42%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[11.42%, 11.42%, 11.42%, 11.42%]
    sparsity=0.10: accuracy=14.19%
    sparsity=0.20: accuracy=14.19%
    sparsity=0.30: accuracy=14.19%
    sparsity=0.40: accuracy=14.19%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[14.19%, 14.19%, 14.19%, 14.19%]
    sparsity=0.10: accuracy=13.44%
    sparsity=0.20: accuracy=13.44%
    sparsity=0.30: accuracy=13.44%
    sparsity=0.40: accuracy=13.44%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[13.44%, 13.44%, 13.44%, 13.44%]
    sparsity=0.10: accuracy=13.44%
    sparsity=0.20: accuracy=13.44%
    sparsity=0.30: accuracy=13.44%
    sparsity=0.40: accuracy=13.44%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[13.44%, 13.44%, 13.44%, 13.44%]
    sparsity=0.10: accuracy=13.44%
    sparsity=0.20: accuracy=13.44%
    sparsity=0.30: accuracy=13.44%
    sparsity=0.40: accuracy=13.44%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[13.44%, 13.44%, 13.44%, 13.44%]
    sparsity=0.10: accuracy=15.13%
    sparsity=0.20: accuracy=15.13%
    sparsity=0.30: accuracy=15.13%
    sparsity=0.40: accuracy=15.13%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[15.13%, 15.13%, 15.13%, 15.13%]
    sparsity=0.10: accuracy=12.12%
    sparsity=0.20: accuracy=12.12%
    sparsity=0.30: accuracy=12.12%
    sparsity=0.40: accuracy=12.12%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[12.12%, 12.12%, 12.12%, 12.12%]
    sparsity=0.10: accuracy=12.12%
    sparsity=0.20: accuracy=12.12%
    sparsity=0.30: accuracy=12.12%
    sparsity=0.40: accuracy=12.12%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[12.12%, 12.12%, 12.12%, 12.12%]
    sparsity=0.10: accuracy=12.12%
    sparsity=0.20: accuracy=12.12%
    sparsity=0.30: accuracy=12.12%
    sparsity=0.40: accuracy=12.12%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[12.12%, 12.12%, 12.12%, 12.12%]
    sparsity=0.10: accuracy=12.48%
    sparsity=0.20: accuracy=12.48%
    sparsity=0.30: accuracy=12.48%
    sparsity=0.40: accuracy=12.48%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[12.48%, 12.48%, 12.48%, 12.48%]
    sparsity=0.10: accuracy=12.48%
    sparsity=0.20: accuracy=12.48%
    sparsity=0.30: accuracy=12.48%
    sparsity=0.40: accuracy=12.48%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[12.48%, 12.48%, 12.48%, 12.48%]
    sparsity=0.10: accuracy=12.83%
    sparsity=0.20: accuracy=12.83%
    sparsity=0.30: accuracy=12.83%
    sparsity=0.40: accuracy=12.83%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[12.83%, 12.83%, 12.83%, 12.83%]
    sparsity=0.10: accuracy=11.41%
    sparsity=0.20: accuracy=11.41%
    sparsity=0.30: accuracy=11.41%
    sparsity=0.40: accuracy=11.41%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[11.41%, 11.41%, 11.41%, 11.41%]
    sparsity=0.10: accuracy=11.41%
    sparsity=0.20: accuracy=11.41%
    sparsity=0.30: accuracy=11.41%
    sparsity=0.40: accuracy=11.41%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[11.41%, 11.41%, 11.41%, 11.41%]
    sparsity=0.10: accuracy=11.41%
    sparsity=0.20: accuracy=11.41%
    sparsity=0.30: accuracy=11.41%
    sparsity=0.40: accuracy=11.41%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[11.41%, 11.41%, 11.41%, 11.41%]
    sparsity=0.10: accuracy=10.47%
    sparsity=0.20: accuracy=10.47%
    sparsity=0.30: accuracy=10.47%
    sparsity=0.40: accuracy=10.47%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[10.47%, 10.47%, 10.47%, 10.47%]
    sparsity=0.10: accuracy=10.62%
    sparsity=0.20: accuracy=10.62%
    sparsity=0.30: accuracy=10.62%
    sparsity=0.40: accuracy=10.62%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[10.62%, 10.62%, 10.62%, 10.62%]
    sparsity=0.10: accuracy=10.62%
    sparsity=0.20: accuracy=10.62%
    sparsity=0.30: accuracy=10.62%
    sparsity=0.40: accuracy=10.62%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[10.62%, 10.62%, 10.62%, 10.62%]
    sparsity=0.10: accuracy=10.62%
    sparsity=0.20: accuracy=10.62%
    sparsity=0.30: accuracy=10.62%
    sparsity=0.40: accuracy=10.62%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[10.62%, 10.62%, 10.62%, 10.62%]
    sparsity=0.10: accuracy=10.59%
    sparsity=0.20: accuracy=10.59%
    sparsity=0.30: accuracy=10.59%
    sparsity=0.40: accuracy=10.59%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[10.59%, 10.59%, 10.59%, 10.59%]
    sparsity=0.10: accuracy=10.59%
    sparsity=0.20: accuracy=10.59%
    sparsity=0.30: accuracy=10.59%
    sparsity=0.40: accuracy=10.59%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[10.59%, 10.59%, 10.59%, 10.59%]
    sparsity=0.10: accuracy=9.54%
    sparsity=0.20: accuracy=9.54%
    sparsity=0.30: accuracy=9.54%
    sparsity=0.40: accuracy=9.54%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[9.54%, 9.54%, 9.54%, 9.54%]
    sparsity=0.10: accuracy=7.19%
    sparsity=0.20: accuracy=7.19%
    sparsity=0.30: accuracy=7.19%
    sparsity=0.40: accuracy=7.19%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[7.19%, 7.19%, 7.19%, 7.19%]
    sparsity=0.10: accuracy=7.19%
    sparsity=0.20: accuracy=7.19%
    sparsity=0.30: accuracy=7.19%
    sparsity=0.40: accuracy=7.19%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[7.19%, 7.19%, 7.19%, 7.19%]
    sparsity=0.10: accuracy=7.19%
    sparsity=0.20: accuracy=7.19%
    sparsity=0.30: accuracy=7.19%
    sparsity=0.40: accuracy=7.19%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[7.19%, 7.19%, 7.19%, 7.19%]
    sparsity=0.10: accuracy=6.67%
    sparsity=0.20: accuracy=6.67%
    sparsity=0.30: accuracy=6.67%
    sparsity=0.40: accuracy=6.67%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[6.67%, 6.67%, 6.67%, 6.67%]
    sparsity=0.10: accuracy=5.86%
    sparsity=0.20: accuracy=5.86%
    sparsity=0.30: accuracy=5.86%
    sparsity=0.40: accuracy=5.86%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[5.86%, 5.86%, 5.86%, 5.86%]
    sparsity=0.10: accuracy=5.86%
    sparsity=0.20: accuracy=5.86%
    sparsity=0.30: accuracy=5.86%
    sparsity=0.40: accuracy=5.86%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[5.86%, 5.86%, 5.86%, 5.86%]
    sparsity=0.10: accuracy=5.86%
    sparsity=0.20: accuracy=5.86%
    sparsity=0.30: accuracy=5.86%
    sparsity=0.40: accuracy=5.86%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[5.86%, 5.86%, 5.86%, 5.86%]
    sparsity=0.10: accuracy=6.01%
    sparsity=0.20: accuracy=6.01%
    sparsity=0.30: accuracy=6.01%
    sparsity=0.40: accuracy=6.01%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[6.01%, 6.01%, 6.01%, 6.01%]
    sparsity=0.10: accuracy=6.28%
    sparsity=0.20: accuracy=6.28%
    sparsity=0.30: accuracy=6.28%
    sparsity=0.40: accuracy=6.28%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[6.28%, 6.28%, 6.28%, 6.28%]
    sparsity=0.10: accuracy=5.61%
    sparsity=0.20: accuracy=5.61%
    sparsity=0.30: accuracy=5.61%
    sparsity=0.40: accuracy=5.61%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[5.61%, 5.61%, 5.61%, 5.61%]
    sparsity=0.10: accuracy=4.00%
    sparsity=0.20: accuracy=4.00%
    sparsity=0.30: accuracy=4.00%
    sparsity=0.40: accuracy=4.00%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[4.00%, 4.00%, 4.00%, 4.00%]
    sparsity=0.10: accuracy=4.00%
    sparsity=0.20: accuracy=4.00%
    sparsity=0.30: accuracy=4.00%
    sparsity=0.40: accuracy=4.00%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[4.00%, 4.00%, 4.00%, 4.00%]
    sparsity=0.10: accuracy=4.00%
    sparsity=0.20: accuracy=4.00%
    sparsity=0.30: accuracy=4.00%
    sparsity=0.40: accuracy=4.00%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[4.00%, 4.00%, 4.00%, 4.00%]
    sparsity=0.10: accuracy=4.12%
    sparsity=0.20: accuracy=4.12%
    sparsity=0.30: accuracy=4.12%
    sparsity=0.40: accuracy=4.12%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[4.12%, 4.12%, 4.12%, 4.12%]
    sparsity=0.10: accuracy=3.12%
    sparsity=0.20: accuracy=3.12%
    sparsity=0.30: accuracy=3.12%
    sparsity=0.40: accuracy=3.12%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[3.12%, 3.12%, 3.12%, 3.12%]
    sparsity=0.10: accuracy=3.12%
    sparsity=0.20: accuracy=3.12%
    sparsity=0.30: accuracy=3.12%
    sparsity=0.40: accuracy=3.12%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[3.12%, 3.12%, 3.12%, 3.12%]
    sparsity=0.10: accuracy=3.12%
    sparsity=0.20: accuracy=3.12%
    sparsity=0.30: accuracy=3.12%
    sparsity=0.40: accuracy=3.12%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[3.12%, 3.12%, 3.12%, 3.12%]
    sparsity=0.10: accuracy=3.22%
    sparsity=0.20: accuracy=3.22%
    sparsity=0.30: accuracy=3.22%
    sparsity=0.40: accuracy=3.22%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[3.22%, 3.22%, 3.22%, 3.22%]
    sparsity=0.10: accuracy=3.44%
    sparsity=0.20: accuracy=3.44%
    sparsity=0.30: accuracy=3.44%
    sparsity=0.40: accuracy=3.44%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[3.44%, 3.44%, 3.44%, 3.44%]
    sparsity=0.10: accuracy=2.96%
    sparsity=0.20: accuracy=2.96%
    sparsity=0.30: accuracy=2.96%
    sparsity=0.40: accuracy=2.96%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[2.96%, 2.96%, 2.96%, 2.96%]
    sparsity=0.10: accuracy=2.70%
    sparsity=0.20: accuracy=2.70%
    sparsity=0.30: accuracy=2.70%
    sparsity=0.40: accuracy=2.70%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[2.70%, 2.70%, 2.70%, 2.70%]
    sparsity=0.10: accuracy=2.70%
    sparsity=0.20: accuracy=2.70%
    sparsity=0.30: accuracy=2.70%
    sparsity=0.40: accuracy=2.70%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[2.70%, 2.70%, 2.70%, 2.70%]
    sparsity=0.10: accuracy=2.70%
    sparsity=0.20: accuracy=2.70%
    sparsity=0.30: accuracy=2.70%
    sparsity=0.40: accuracy=2.70%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[2.70%, 2.70%, 2.70%, 2.70%]
    sparsity=0.10: accuracy=2.47%
    sparsity=0.20: accuracy=2.47%
    sparsity=0.30: accuracy=2.47%
    sparsity=0.40: accuracy=2.47%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[2.47%, 2.47%, 2.47%, 2.47%]
    sparsity=0.10: accuracy=1.55%
    sparsity=0.20: accuracy=1.55%
    sparsity=0.30: accuracy=1.55%
    sparsity=0.40: accuracy=1.55%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[1.55%, 1.55%, 1.55%, 1.55%]
    sparsity=0.10: accuracy=1.55%
    sparsity=0.20: accuracy=1.55%
    sparsity=0.30: accuracy=1.55%
    sparsity=0.40: accuracy=1.55%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[1.55%, 1.55%, 1.55%, 1.55%]
    sparsity=0.10: accuracy=1.55%
    sparsity=0.20: accuracy=1.55%
    sparsity=0.30: accuracy=1.55%
    sparsity=0.40: accuracy=1.55%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[1.55%, 1.55%, 1.55%, 1.55%]
    sparsity=0.10: accuracy=1.71%
    sparsity=0.20: accuracy=1.71%
    sparsity=0.30: accuracy=1.71%
    sparsity=0.40: accuracy=1.71%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[1.71%, 1.71%, 1.71%, 1.71%]
    sparsity=0.10: accuracy=1.54%
    sparsity=0.20: accuracy=1.54%
    sparsity=0.30: accuracy=1.54%
    sparsity=0.40: accuracy=1.54%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[1.54%, 1.54%, 1.54%, 1.54%]
    sparsity=0.10: accuracy=1.21%
    sparsity=0.20: accuracy=1.21%
    sparsity=0.30: accuracy=1.21%
    sparsity=0.40: accuracy=1.21%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[1.21%, 1.21%, 1.21%, 1.21%]
    sparsity=0.10: accuracy=1.91%
    sparsity=0.20: accuracy=1.91%
    sparsity=0.30: accuracy=1.91%
    sparsity=0.40: accuracy=1.91%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[1.91%, 1.91%, 1.91%, 1.91%]
    sparsity=0.10: accuracy=1.91%
    sparsity=0.20: accuracy=1.91%
    sparsity=0.30: accuracy=1.91%
    sparsity=0.40: accuracy=1.91%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[1.91%, 1.91%, 1.91%, 1.91%]
    sparsity=0.10: accuracy=1.91%
    sparsity=0.20: accuracy=1.91%
    sparsity=0.30: accuracy=1.91%
    sparsity=0.40: accuracy=1.91%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[1.91%, 1.91%, 1.91%, 1.91%]
    sparsity=0.10: accuracy=1.97%
    sparsity=0.20: accuracy=1.97%
    sparsity=0.30: accuracy=1.97%
    sparsity=0.40: accuracy=1.97%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[1.97%, 1.97%, 1.97%, 1.97%]
    sparsity=0.10: accuracy=1.85%
    sparsity=0.20: accuracy=1.85%
    sparsity=0.30: accuracy=1.85%
    sparsity=0.40: accuracy=1.85%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[1.85%, 1.85%, 1.85%, 1.85%]
    sparsity=0.10: accuracy=1.85%
    sparsity=0.20: accuracy=1.85%
    sparsity=0.30: accuracy=1.85%
    sparsity=0.40: accuracy=1.85%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[1.85%, 1.85%, 1.85%, 1.85%]
    sparsity=0.10: accuracy=1.85%
    sparsity=0.20: accuracy=1.85%
    sparsity=0.30: accuracy=1.85%
    sparsity=0.40: accuracy=1.85%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[1.85%, 1.85%, 1.85%, 1.85%]
    sparsity=0.10: accuracy=1.87%
    sparsity=0.20: accuracy=1.87%
    sparsity=0.30: accuracy=1.87%
    sparsity=0.40: accuracy=1.87%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[1.87%, 1.87%, 1.87%, 1.87%]
    sparsity=0.10: accuracy=1.77%
    sparsity=0.20: accuracy=1.77%
    sparsity=0.30: accuracy=1.77%
    sparsity=0.40: accuracy=1.77%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[1.77%, 1.77%, 1.77%, 1.77%]
    sparsity=0.10: accuracy=1.63%
    sparsity=0.20: accuracy=1.63%
    sparsity=0.30: accuracy=1.63%
    sparsity=0.40: accuracy=1.63%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[1.63%, 1.63%, 1.63%, 1.63%]
    sparsity=0.10: accuracy=1.40%
    sparsity=0.20: accuracy=1.40%
    sparsity=0.30: accuracy=1.40%
    sparsity=0.40: accuracy=1.40%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[1.40%, 1.40%, 1.40%, 1.40%]
    sparsity=0.10: accuracy=1.40%
    sparsity=0.20: accuracy=1.40%
    sparsity=0.30: accuracy=1.40%
    sparsity=0.40: accuracy=1.40%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[1.40%, 1.40%, 1.40%, 1.40%]
    sparsity=0.10: accuracy=1.40%
    sparsity=0.20: accuracy=1.40%
    sparsity=0.30: accuracy=1.40%
    sparsity=0.40: accuracy=1.40%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[1.40%, 1.40%, 1.40%, 1.40%]
    sparsity=0.10: accuracy=1.37%
    sparsity=0.20: accuracy=1.37%
    sparsity=0.30: accuracy=1.37%
    sparsity=0.40: accuracy=1.37%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[1.37%, 1.37%, 1.37%, 1.37%]
    sparsity=0.10: accuracy=1.50%
    sparsity=0.20: accuracy=1.50%
    sparsity=0.30: accuracy=1.50%
    sparsity=0.40: accuracy=1.50%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[1.50%, 1.50%, 1.50%, 1.50%]
    sparsity=0.10: accuracy=1.50%
    sparsity=0.20: accuracy=1.50%
    sparsity=0.30: accuracy=1.50%
    sparsity=0.40: accuracy=1.50%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[1.50%, 1.50%, 1.50%, 1.50%]
    sparsity=0.10: accuracy=1.50%
    sparsity=0.20: accuracy=1.50%
    sparsity=0.30: accuracy=1.50%
    sparsity=0.40: accuracy=1.50%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[1.50%, 1.50%, 1.50%, 1.50%]
    sparsity=0.10: accuracy=1.54%
    sparsity=0.20: accuracy=1.54%
    sparsity=0.30: accuracy=1.54%
    sparsity=0.40: accuracy=1.54%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[1.54%, 1.54%, 1.54%, 1.54%]
    sparsity=0.10: accuracy=1.52%
    sparsity=0.20: accuracy=1.52%
    sparsity=0.30: accuracy=1.52%
    sparsity=0.40: accuracy=1.52%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[1.52%, 1.52%, 1.52%, 1.52%]
    sparsity=0.10: accuracy=1.52%
    sparsity=0.20: accuracy=1.52%
    sparsity=0.30: accuracy=1.52%
    sparsity=0.40: accuracy=1.52%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[1.52%, 1.52%, 1.52%, 1.52%]
    sparsity=0.10: accuracy=0.77%
    sparsity=0.20: accuracy=0.77%
    sparsity=0.30: accuracy=0.77%
    sparsity=0.40: accuracy=0.77%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[0.77%, 0.77%, 0.77%, 0.77%]
    sparsity=0.10: accuracy=0.77%
    sparsity=0.20: accuracy=0.77%
    sparsity=0.30: accuracy=0.77%
    sparsity=0.40: accuracy=0.77%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[0.77%, 0.77%, 0.77%, 0.77%]
    sparsity=0.10: accuracy=0.69%
    sparsity=0.20: accuracy=0.69%
    sparsity=0.30: accuracy=0.69%
    sparsity=0.40: accuracy=0.69%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[0.69%, 0.69%, 0.69%, 0.69%]
    sparsity=0.10: accuracy=0.69%
    sparsity=0.20: accuracy=0.69%
    sparsity=0.30: accuracy=0.69%
    sparsity=0.40: accuracy=0.69%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[0.69%, 0.69%, 0.69%, 0.69%]
    sparsity=0.10: accuracy=0.69%
    sparsity=0.20: accuracy=0.69%
    sparsity=0.30: accuracy=0.69%
    sparsity=0.40: accuracy=0.69%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[0.69%, 0.69%, 0.69%, 0.69%]
    sparsity=0.10: accuracy=0.65%
    sparsity=0.20: accuracy=0.65%
    sparsity=0.30: accuracy=0.65%
    sparsity=0.40: accuracy=0.65%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[0.65%, 0.65%, 0.65%, 0.65%]
    sparsity=0.10: accuracy=0.62%
    sparsity=0.20: accuracy=0.62%
    sparsity=0.30: accuracy=0.62%
    sparsity=0.40: accuracy=0.62%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[0.62%, 0.62%, 0.62%, 0.62%]
    sparsity=0.10: accuracy=0.64%
    sparsity=0.20: accuracy=0.64%
    sparsity=0.30: accuracy=0.64%
    sparsity=0.40: accuracy=0.64%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[0.64%, 0.64%, 0.64%, 0.64%]
    sparsity=0.10: accuracy=0.66%
    sparsity=0.20: accuracy=0.66%
    sparsity=0.30: accuracy=0.66%
    sparsity=0.40: accuracy=0.66%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[0.66%, 0.66%, 0.66%, 0.66%]
    sparsity=0.10: accuracy=0.66%
    sparsity=0.20: accuracy=0.66%
    sparsity=0.30: accuracy=0.66%
    sparsity=0.40: accuracy=0.66%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[0.66%, 0.66%, 0.66%, 0.66%]
    sparsity=0.10: accuracy=0.66%
    sparsity=0.20: accuracy=0.66%
    sparsity=0.30: accuracy=0.66%
    sparsity=0.40: accuracy=0.66%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[0.66%, 0.66%, 0.66%, 0.66%]
    sparsity=0.10: accuracy=0.65%
    sparsity=0.20: accuracy=0.65%
    sparsity=0.30: accuracy=0.65%
    sparsity=0.40: accuracy=0.65%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[0.65%, 0.65%, 0.65%, 0.65%]
    sparsity=0.10: accuracy=0.29%
    sparsity=0.20: accuracy=0.29%
    sparsity=0.30: accuracy=0.29%
    sparsity=0.40: accuracy=0.29%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[0.29%, 0.29%, 0.29%, 0.29%]
    sparsity=0.10: accuracy=0.29%
    sparsity=0.20: accuracy=0.29%
    sparsity=0.30: accuracy=0.29%
    sparsity=0.40: accuracy=0.29%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[0.29%, 0.29%, 0.29%, 0.29%]
    sparsity=0.10: accuracy=0.25%
    sparsity=0.20: accuracy=0.25%
    sparsity=0.30: accuracy=0.25%
    sparsity=0.40: accuracy=0.25%sparsity=[0.10,0.20,0.30,0.40]: accuracy=[0.25%, 0.25%, 0.25%, 0.25%]